{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelerucci/opt/anaconda3/envs/mycondaenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import wandb\n",
    "from lightly.loss.ntx_ent_loss import NTXentLoss\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, resnet18\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets.data import ShapeNetRender, ModelNet40SVM\n",
    "from models.dgcnn import DGCNN, ResNet, DGCNN_partseg\n",
    "from util import IOStream, AverageMeter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COSTANTI\n",
    "exp_name = 'exp' # Name of the experiment\n",
    "model = 'dgcnn' # Model to use, [pointnet, dgcnn]\n",
    "batch_size = 16 # Size of batch)\n",
    "test_batch_size = 16 # Size of batch)\n",
    "epochs = 250 # number of episode to train\n",
    "start_epoch = 0  # number of episode to train\n",
    "use_sgd_action = 'store_true' # Use SGD\n",
    "lr = 0.001 # learning rate (default: 0.001, 0.1 if using sgd)\n",
    "momentum = 0.9 # SGD momentum (default: 0.9)\n",
    "no_cuda = False # enables CUDA training\n",
    "seed = 1 # random seed (default: 1)'\n",
    "evalu = False # evaluate the model\n",
    "num_points = 2048 # num of points to use\n",
    "dropout = 0.5 # dropout rate\n",
    "emb_dims = 1024 # Dimension of embeddings\n",
    "k = 20 # Num of nearest neighbors to use\n",
    "resume_action = 'store_true'  # resume from checkpoint\n",
    "model_path = '' # Pretrained model path\n",
    "save_freq = 50 # save frequency\n",
    "print_freq = 50 # print frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('checkpoints'):\n",
    "    os.makedirs('checkpoints')\n",
    "if not os.path.exists('checkpoints/'+exp_name):\n",
    "    os.makedirs('checkpoints/'+exp_name)\n",
    "if not os.path.exists('checkpoints/'+exp_name+'/'+'models'):\n",
    "    os.makedirs('checkpoints/'+exp_name+'/'+'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (exp_name,model,batch_size,test_batch_size,epochs,start_epoch,use_sgd_action,lr,momentum,no_cuda,seed,evalu,num_points,dropout, emb_dims,k,resume_action,model_path,save_freq,print_freq, io):\n",
    "    print('ciao')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "ciao\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "io = IOStream('checkpoints/' + exp_name + '/run.log')\n",
    "    #io.cprint(str(args))\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    io.cprint(\n",
    "        'Using GPU : ' + str(torch.cuda.current_device()) + ' from ' + str(torch.cuda.device_count()) + ' devices')\n",
    "    torch.cuda.manual_seed(seed)\n",
    "else:\n",
    "    io.cprint('Using CPU')\n",
    "\n",
    "if not evalu:\n",
    "    train(exp_name , model , batch_size, test_batch_size, epochs, start_epoch, use_sgd_action, lr, momentum, no_cuda,seed , evalu, num_points, dropout, emb_dims, k, resume_action, model_path, save_freq, print_freq,io)\n",
    "# else:\n",
    "#     test(args, io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cli_main():\n",
    "    # ------------\n",
    "    # args\n",
    "    # ------------\n",
    "    parser = argparse.ArgumentParser(description='Point Cloud Recognition')\n",
    "    parser.add_argument('--exp_name', type=str, default='exp', metavar='N',help='Name of the experiment')\n",
    "    parser.add_argument('--model', type=str, default='dgcnn', metavar='N',choices=['dgcnn', 'dgcnn_seg'],help='Model to use, [pointnet, dgcnn]')\n",
    "    parser.add_argument('--batch_size', type=int, default=16, metavar='batch_size',help='Size of batch)')\n",
    "    parser.add_argument('--test_batch_size', type=int, default=16, metavar='batch_size',help='Size of batch)')\n",
    "    parser.add_argument('--epochs', type=int, default=250, metavar='N',help='number of episode to train ')\n",
    "    parser.add_argument('--start_epoch', type=int, default=0, metavar='N',help='number of episode to train ')\n",
    "    parser.add_argument('--use_sgd', action=\"store_true\", help='Use SGD')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',help='learning rate (default: 0.001, 0.1 if using sgd)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--no_cuda', type=bool, default=False,help='enables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',help='random seed (default: 1)')\n",
    "    parser.add_argument('--eval', type=bool,  default=False,help='evaluate the model')\n",
    "    parser.add_argument('--num_points', type=int, default=2048,help='num of points to use')\n",
    "    parser.add_argument('--dropout', type=float, default=0.5,help='dropout rate')\n",
    "    parser.add_argument('--emb_dims', type=int, default=1024, metavar='N', help='Dimension of embeddings')\n",
    "    parser.add_argument('--k', type=int, default=20, metavar='N', help='Num of nearest neighbors to use')\n",
    "    parser.add_argument('--resume', action=\"store_true\", help='resume from checkpoint')\n",
    "    parser.add_argument('--model_path', type=str, default='', metavar='N', help='Pretrained model path')\n",
    "    parser.add_argument('--save_freq', type=int, default=50, help='save frequency')\n",
    "    parser.add_argument('--print_freq', type=int, default=50, help='print frequency')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    # ------------\n",
    "    # data\n",
    "    # ------------\n",
    "    transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    train_loader = DataLoader(ShapeNetRender(transform, n_imgs = 2), num_workers=0, batch_size=args.batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--exp_name N] [--model N]\n",
      "                             [--batch_size batch_size]\n",
      "                             [--test_batch_size batch_size] [--epochs N]\n",
      "                             [--start_epoch N] [--use_sgd] [--lr LR]\n",
      "                             [--momentum M] [--no_cuda NO_CUDA] [--seed S]\n",
      "                             [--eval EVAL] [--num_points NUM_POINTS]\n",
      "                             [--dropout DROPOUT] [--emb_dims N] [--k N]\n",
      "                             [--resume] [--model_path N]\n",
      "                             [--save_freq SAVE_FREQ] [--print_freq PRINT_FREQ]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/emanuelerucci/Library/Jupyter/runtime/kernel-494e94c5-1466-4235-9e7e-a3fca30f45fb.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cli_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "class Model1(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer1(x)\n",
    "\n",
    "class Model2(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer1(x)\n",
    "\n",
    "class TotalModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model1 = Model1()\n",
    "        self.model2 = Model2()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        x = self.model2(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "        return optimizer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycondaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00ef58c8c6b1efa69c136d92d35afade413d2c5faa6bb3e7af0113bc3f2806ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
